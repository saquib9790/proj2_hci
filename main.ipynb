{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02fb3d73a41145c7841d174470da1642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c549b33f494e58af73fd0994324bf5",
              "IPY_MODEL_c8b14b5805514eeba097ee51aa8ba434",
              "IPY_MODEL_bf8103de8880429f89c6250d92a2d639"
            ],
            "layout": "IPY_MODEL_8f3aca9f01c34f7dacf59ab40e58e827"
          }
        },
        "85c549b33f494e58af73fd0994324bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ff422712f543a680eff139ab1ec265",
            "placeholder": "​",
            "style": "IPY_MODEL_15baee2133804fdca69fe346dfbfc355",
            "value": "Fetching 2 files: 100%"
          }
        },
        "c8b14b5805514eeba097ee51aa8ba434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c8424303a1a49f297cceb9f24f888f1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e017e7a04b8430f9e9f28f753bc30dd",
            "value": 2
          }
        },
        "bf8103de8880429f89c6250d92a2d639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf955caa4944087b97cbabb48175a3c",
            "placeholder": "​",
            "style": "IPY_MODEL_32132d3b5aea4a1ba8fe774c5fdbcc40",
            "value": " 2/2 [00:00&lt;00:00, 250.06it/s]"
          }
        },
        "8f3aca9f01c34f7dacf59ab40e58e827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ff422712f543a680eff139ab1ec265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15baee2133804fdca69fe346dfbfc355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c8424303a1a49f297cceb9f24f888f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e017e7a04b8430f9e9f28f753bc30dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf955caa4944087b97cbabb48175a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32132d3b5aea4a1ba8fe774c5fdbcc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub tensorflow matplotlib numpy\n",
        "\n",
        "import os, zipfile, random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "import matplotlib.pyplot as plt\n",
        "from huggingface_hub import snapshot_download\n",
        "import pandas as pd\n",
        "from glob import glob\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE8H2MILlS71",
        "outputId": "81152141-dc07-471a-d8de-46a6fad14bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = snapshot_download(\n",
        "    repo_id=\"YCAI3/HCI_P2\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"./HCI_Dataset\",\n",
        "    ignore_patterns=[\".gitattributes\"]\n",
        ")\n",
        "\n",
        "print(\"Dataset downloaded to:\", dataset_dir)\n",
        "\n",
        "zip_path = os.path.join(dataset_dir, \"HCI_Dataset.zip\")\n",
        "extract_dir = os.path.join(dataset_dir, \"unzipped\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"✅ Extracted to:\", extract_dir)\n",
        "print(\"Subfolders:\", os.listdir(extract_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "02fb3d73a41145c7841d174470da1642",
            "85c549b33f494e58af73fd0994324bf5",
            "c8b14b5805514eeba097ee51aa8ba434",
            "bf8103de8880429f89c6250d92a2d639",
            "8f3aca9f01c34f7dacf59ab40e58e827",
            "a4ff422712f543a680eff139ab1ec265",
            "15baee2133804fdca69fe346dfbfc355",
            "1c8424303a1a49f297cceb9f24f888f1",
            "1e017e7a04b8430f9e9f28f753bc30dd",
            "fdf955caa4944087b97cbabb48175a3c",
            "32132d3b5aea4a1ba8fe774c5fdbcc40"
          ]
        },
        "id": "-voTIWisIFSF",
        "outputId": "2bb17f0e-d6ab-47f7-f527-121033088e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02fb3d73a41145c7841d174470da1642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to: ./HCI_Dataset/unzipped/HCI_Dataset\n",
            "Sample subfolders: ['50', '10', '198', '53', '195']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"./HCI_Dataset/unzipped/HCI_Dataset\"\n",
        "\n",
        "image_paths = glob(os.path.join(base_path, \"**\", \"*.jpg\"), recursive=True)\n",
        "print(\"Total images found:\", len(image_paths))\n",
        "print(\"Example paths:\\n\", image_paths[:5])\n",
        "\n",
        "# Extract label from filename (the word between underscores)\n",
        "def get_label_from_path(path):\n",
        "    filename = os.path.basename(path)\n",
        "    parts = filename.split(\"_\")\n",
        "    if len(parts) >= 3:\n",
        "        return parts[1]\n",
        "    return None\n",
        "\n",
        "labels = [get_label_from_path(p) for p in image_paths]\n",
        "data = pd.DataFrame({\"path\": image_paths, \"label\": labels})\n",
        "\n",
        "print(\"\\nRandom samples:\")\n",
        "print(data.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywrZ65U3IF8T",
        "outputId": "c3d6193b-0d2f-4394-a010-9a1cf3306a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 609656\n",
            "✅ Using subset of 15000 samples\n",
            "                                                   path          label\n",
            "7550  ./HCI_Dataset/unzipped/HCI_Dataset/25/2/301_TU...        TUCUMAN\n",
            "120   ./HCI_Dataset/unzipped/HCI_Dataset/56/4/310_su...  supernumerary\n",
            "1833  ./HCI_Dataset/unzipped/HCI_Dataset/92/2/464_LO...          LOOPY\n",
            "6714  ./HCI_Dataset/unzipped/HCI_Dataset/87/2/493_Ut...        Utterly\n",
            "3740  ./HCI_Dataset/unzipped/HCI_Dataset/151/2/21_in...      inoculate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 4: Visualize a Random Sample ---\n",
        "IMG_HEIGHT, IMG_WIDTH = 64, 256  # Wider for text\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=1)\n",
        "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "sample_idx = random.randint(0, len(data) - 1)\n",
        "img = load_and_preprocess_image(data[\"path\"][sample_idx])\n",
        "\n",
        "plt.imshow(tf.squeeze(img), cmap=\"gray\")\n",
        "plt.title(f\"Label: {data['label'][sample_idx]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Sample path:\", data['path'][sample_idx])\n",
        "print(\"Extracted label:\", data['label'][sample_idx])\n",
        "print(\"File exists:\", os.path.exists(data['path'][sample_idx]))\n"
      ],
      "metadata": {
        "id": "WnRcic88IHeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bb175f-13b2-494a-8bca-d6856d323634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary sample: ['0', '1', '2', '3', '4', '5', '6', '7', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']\n",
            "Total unique characters (including blank): 62\n",
            "Original: Ernst\n",
            "Encoded: [14 53 49 54 55]\n",
            "Decoded: Ernst\n",
            "char_to_num vocab: ['[UNK]', np.str_('0'), np.str_('1'), np.str_('2'), np.str_('3'), np.str_('4'), np.str_('5'), np.str_('6'), np.str_('7'), np.str_('9'), np.str_('A'), np.str_('B'), np.str_('C'), np.str_('D'), np.str_('E')]\n",
            "num_to_char vocab: ['[UNK]', np.str_('0'), np.str_('1'), np.str_('2'), np.str_('3'), np.str_('4'), np.str_('5'), np.str_('6'), np.str_('7'), np.str_('9'), np.str_('A'), np.str_('B'), np.str_('C'), np.str_('D'), np.str_('E')]\n",
            "Blank token index: tf.Tensor(62, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 5: Character Encoding ---\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "\n",
        "# Collect all unique characters from labels\n",
        "all_text = \"\".join(data[\"label\"].astype(str).tolist())\n",
        "unique_chars = sorted(list(set(all_text)))\n",
        "\n",
        "print(\"Unique characters:\", unique_chars)\n",
        "print(\"Total unique characters:\", len(unique_chars))\n",
        "\n",
        "# Build lookup tables\n",
        "char_to_num = StringLookup(vocabulary=unique_chars, oov_token=\"\")\n",
        "num_to_char = StringLookup(vocabulary=char_to_num.get_vocabulary(), invert=True)\n",
        "\n",
        "# Quick test\n",
        "example = data[\"label\"].iloc[0]\n",
        "encoded = char_to_num(tf.strings.unicode_split(example, input_encoding=\"UTF-8\"))\n",
        "decoded = tf.strings.reduce_join(num_to_char(encoded)).numpy().decode(\"utf-8\")\n",
        "print(f\"Original: {example}\\nDecoded : {decoded}\")\n"
      ],
      "metadata": {
        "id": "lKls3OyqII_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 6: Dataset Creation and Preprocessing ---\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH = 64, 256  # consistent with earlier\n",
        "\n",
        "def preprocess(path, label):\n",
        "    # Load image\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=1)\n",
        "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
        "    img = img / 255.0\n",
        "\n",
        "    # Encode text to integer sequence\n",
        "    label = char_to_num(tf.strings.unicode_split(label, 'UTF-8'))\n",
        "    return img, label\n",
        "\n",
        "paths = data[\"path\"].tolist()\n",
        "labels = data[\"label\"].tolist()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "Ysa6zUlw9DyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 7: Split Dataset and Batch ---\n",
        "total_size = len(data)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size   = int(0.1 * total_size)\n",
        "\n",
        "train_ds = dataset.take(train_size)\n",
        "val_ds   = dataset.skip(train_size).take(val_size)\n",
        "test_ds  = dataset.skip(train_size + val_size)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_ds = (\n",
        "    train_ds.padded_batch(BATCH_SIZE, padded_shapes=([64, 256, 1], [None]))\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "val_ds = (\n",
        "    val_ds.padded_batch(BATCH_SIZE, padded_shapes=([64, 256, 1], [None]))\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "IWGEs5KO9Ep4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 8: Visualize a Batch and Check Encoding ---\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    idx = 0\n",
        "    plt.imshow(tf.squeeze(images[idx]), cmap='gray')\n",
        "    decoded_label = tf.strings.reduce_join(num_to_char(labels[idx])).numpy().decode('utf-8')\n",
        "    plt.title(f\"Decoded: {decoded_label}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"Image shape:\", images.shape)\n",
        "print(\"Label shape:\", labels.shape)\n"
      ],
      "metadata": {
        "id": "kF-g6Wst9GHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 9: Define CTC Loss Function ---\n",
        "\n",
        "def ctc_loss_func(y_true, y_pred):\n",
        "    # Compute sequence lengths\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_len = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_len = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_len * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_len * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "FD0yAB9I9H4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 10: Build CRNN Architecture ---\n",
        "def build_crnn(rnn_type=\"lstm\"):\n",
        "    input_img = layers.Input(shape=(64, 256, 1), name=\"image\")\n",
        "\n",
        "    # --- CNN feature extractor ---\n",
        "    x = layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(input_img)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Reshape features for RNN\n",
        "    new_shape = ((64 // 8), (256 // 8) * 128)  # adjust pooling math\n",
        "    x = layers.Reshape(target_shape=new_shape)(x)\n",
        "\n",
        "    # --- RNN feature sequence ---\n",
        "    if rnn_type.lower() == \"gru\":\n",
        "        x = layers.Bidirectional(layers.GRU(128, return_sequences=True))(x)\n",
        "        x = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x)\n",
        "    else:\n",
        "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "\n",
        "    # --- Dense + Softmax output ---\n",
        "    x = layers.Dense(len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=input_img, outputs=x, name=f\"CRNN_{rnn_type.upper()}\")\n",
        "    return model\n",
        "\n",
        "# Build both variants for later\n",
        "crnn_lstm = build_crnn(\"lstm\")\n",
        "crnn_gru  = build_crnn(\"gru\")\n",
        "\n",
        "crnn_lstm.summary()\n"
      ],
      "metadata": {
        "id": "_cYCvPuH9RXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 11: Train CRNN (LSTM + Adam) ---\n",
        "crnn_lstm = build_crnn(\"lstm\")\n",
        "crnn_lstm.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=ctc_loss_func\n",
        ")\n",
        "\n",
        "history_lstm_adam = crnn_lstm.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "crnn_lstm.save(\"crnn_lstm_adam.h5\")"
      ],
      "metadata": {
        "id": "8-Fg0oaU_RbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 12: Train CRNN (LSTM + SGD) ---\n",
        "crnn_lstm_sgd = build_crnn(\"lstm\")\n",
        "crnn_lstm_sgd.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9),\n",
        "    loss=ctc_loss_func\n",
        ")\n",
        "\n",
        "history_lstm_sgd = crnn_lstm_sgd.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "crnn_lstm_sgd.save(\"crnn_lstm_sgd.h5\")"
      ],
      "metadata": {
        "id": "1tx0RuIw_Xjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 13: Train CRNN (GRU + Adam) ---\n",
        "crnn_gru = build_crnn(\"gru\")\n",
        "crnn_gru.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=ctc_loss_func\n",
        ")\n",
        "\n",
        "history_gru_adam = crnn_gru.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "crnn_gru.save(\"crnn_gru_adam.h5\")"
      ],
      "metadata": {
        "id": "k9dQkNEe_Y6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 14: Train CRNN (GRU + SGD) ---\n",
        "crnn_gru_sgd = build_crnn(\"gru\")\n",
        "crnn_gru_sgd.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9),\n",
        "    loss=ctc_loss_func\n",
        ")\n",
        "\n",
        "history_gru_sgd = crnn_gru_sgd.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "crnn_gru_sgd.save(\"crnn_gru_sgd.h5\")"
      ],
      "metadata": {
        "id": "MC15D7Zi_b0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 15: Compare All Models' Training Histories ---\n",
        "def plot_history(history, title):\n",
        "    plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"CTC Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_lstm_adam, \"LSTM + Adam\")\n",
        "plot_history(history_lstm_sgd, \"LSTM + SGD\")\n",
        "plot_history(history_gru_adam, \"GRU + Adam\")\n",
        "plot_history(history_gru_sgd, \"GRU + SGD\")"
      ],
      "metadata": {
        "id": "Ytvf7oMg_eDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}